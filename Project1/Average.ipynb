{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    return np.loadtxt(open(filename), delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "data = load_data('train_2008.csv')\n",
    "X = data[:, 1:-1]\n",
    "y = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(y) #64667\n",
    "D = len(X[0]) #381\n",
    "\n",
    "# Split to train / test (validation) data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample, y_sample = X_train[:1000], y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load real test data\n",
    "test_data = load_data('test_2008.csv')\n",
    "X_test_real = test_data[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting \n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_score_gbr = gbr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lgr = LogisticRegression(C = 0.1, penalty = 'l1')\n",
    "lgr.fit(X_train, y_train)\n",
    "pred_prob = lgr.predict_proba(X_test)\n",
    "y_scores_lgr = pred_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find features with the most contribution\n",
    "\n",
    "weights = lgr.coef_.flatten()\n",
    "top_idxs = np.argsort(abs(weights))[-10:]\n",
    "features = np.loadtxt(open('test_2008.csv'), delimiter=',', dtype='str')[0, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features[top_idxs])\n",
    "[weights[i] for i in top_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = list(lgr.coef_[0])\n",
    "\n",
    "for w in weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "regr = RandomForestRegressor(n_estimators = 100, max_features = 26)\n",
    "regr.fit(X_train, y_train)\n",
    "y_score_regr = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average of the three\n",
    "y_test_scores = 0.4*y_score_gbr + 0.3*y_scores_lgr + 0.3*y_score_regr\n",
    "\n",
    "\n",
    "y_test_scores = y_test_scores.clip(min=0)\n",
    "roc_auc_score(y_test, y_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on the entire training data\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X, y)\n",
    "\n",
    "# Load real test data\n",
    "test_data = load_data('test_2008.csv')\n",
    "X_test_real = test_data[:, 1:]\n",
    "\n",
    "# Output results on the actual test data\n",
    "y_test_scores = gbr.predict(X_test_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_scores = y_test_scores.clip(min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('sub1.csv', 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerow(['id', 'target'])\n",
    "    for i in range(0, 16000):\n",
    "        writer.writerow([i, y_test_scores[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Regressor with Grid Search\n",
    "gbr = GradientBoostingRegressor()\n",
    "\n",
    "param_grid={'n_estimators':[100,200,500], \n",
    "            'learning_rate': [0.1,0.05,0.02],\n",
    "            'max_depth':[3,4], \n",
    "            'min_samples_leaf':[1,2,3], \n",
    "            'max_features':[None,1.0] } \n",
    "\n",
    "gbr = GridSearchCV(estimator=gbr, cv=5, param_grid=param_grid, \n",
    "    n_jobs=4)\n",
    "\n",
    "gbr.fit(X_sample, y_sample)\n",
    "y_score_gbr = gbr.predict(X_test)\n",
    "\n",
    "print(roc_auc_score(y_test, y_score_gbr))\n",
    "\n",
    "print(gbr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
