{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(open(\"train_2008.csv\", \"rb\"), delimiter=\",\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, 1:-1]\n",
    "y = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(y) #381\n",
    "D = len(X[0]) #64667\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample, y_sample = X_train[:1000], y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up data (get rid of columns with 0 std)\n",
    "X_std = np.std(X, axis=0)\n",
    "X = X[:, np.where(X_std!=0)]\n",
    "X = X.reshape(64667, 366)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Normalize\n",
    "X_mean = np.mean(X, axis=0)\n",
    "X_std = np.std(X, axis=0)\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoosting():\n",
    "    def __init__(self, n_clfs=100):\n",
    "        '''\n",
    "        Initialize the gradient boosting model.\n",
    "\n",
    "        Inputs:\n",
    "            n_clfs (default 100): Initializer for self.n_clfs.        \n",
    "                \n",
    "        Attributes:\n",
    "            self.n_clfs: The number of DT weak regressors.\n",
    "            self.clfs: A list of the DT weak regressors, initialized as empty.\n",
    "        '''\n",
    "        self.n_clfs = n_clfs\n",
    "        self.clfs = []\n",
    "        \n",
    "    def fit(self, X, Y, n_nodes=4):\n",
    "        '''\n",
    "        Fit the gradient boosting model by training self.n_clfs DT weak regressors and store them in self.clfs.\n",
    "\n",
    "        Inputs:\n",
    "            X: A (N, D) shaped numpy array containing the data points.\n",
    "            Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
    "               (Even though the labels are ints, we treat them as floats.)\n",
    "            n_nodes: The max number of nodes that the DT weak regressors are allowed to have.\n",
    "        '''\n",
    "        # store predictions from previous weak regressors to train on residuals\n",
    "        predictions = np.zeros(shape=(len(Y), ))\n",
    "        \n",
    "        for i in range(self.n_clfs):\n",
    "            clf = DecisionTreeRegressor(max_leaf_nodes=n_nodes)\n",
    "            clf.fit(X, Y - predictions)\n",
    "            self.clfs.append(clf)\n",
    "            predictions += clf.predict(X)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predict on the given dataset.\n",
    "\n",
    "        Inputs:\n",
    "            X: A (N, D) shaped numpy array containing the data points.\n",
    "\n",
    "        Outputs:\n",
    "            A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
    "            (Even though the labels are ints, we treat them as floats.)\n",
    "        '''\n",
    "        # Initialize predictions.\n",
    "        Y_pred = np.zeros(len(X))\n",
    "        \n",
    "        # Add predictions from each DT weak regressor.\n",
    "        for clf in self.clfs:\n",
    "            Y_curr = clf.predict(X)\n",
    "            Y_pred += Y_curr\n",
    "\n",
    "        # Return the sign of the predictions.\n",
    "        return Y_pred\n",
    "\n",
    "    def loss(self, X, Y):\n",
    "        '''\n",
    "        Calculate the classification loss.\n",
    "\n",
    "        Inputs:\n",
    "            X: A (N, D) shaped numpy array containing the data points.\n",
    "            Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
    "               (Even though the labels are ints, we treat them as floats.)\n",
    "            \n",
    "        Outputs:\n",
    "            The classification loss.\n",
    "        '''\n",
    "        # Calculate the points where the predictions and the ground truths don't match.\n",
    "        Y_pred = self.predict(X)\n",
    "        misclassified = np.where(Y_pred != Y)[0]\n",
    "\n",
    "        # Return the fraction of such points.\n",
    "        return float(len(misclassified)) / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoosting()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7681639776574813"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
